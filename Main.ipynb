{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "resources = importlib.import_module(\"resources\")\n",
    "import resources.MonteCarlo as MC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import random\n",
    "random.seed(2010)\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing random variable with distribution uniform distribution from x=1:5,\n",
      " 841\n",
      "\n",
      "New simulator for generator for two linear functions from x=1:5,\n",
      " with uniform distribution from x=1:5 input\n",
      "(309.84360627884854, -1.3743289366239595)\n",
      "(294.6563461032461, -1.3058583100563865)\n",
      "(931.0029156391859, 1.2451209369775529)\n",
      "(315.7913121258354, 1.5333334910892942)\n",
      "(982.7026854892948, 982.2536003611793)\n",
      "(973.4587463627327, 1.261361454726381)\n",
      "(127.63541995507055, 0.007742442216441369)\n",
      "(961.1829041289427, -0.3395306129214694)\n",
      "(72.47215892759907, -1.1766043284662968)\n",
      "(361.71581052000346, 361.6472788719758)\n"
     ]
    }
   ],
   "source": [
    "inv_f = lambda x : MC.inverse_uniform(x,0,1000)\n",
    "X = MC.RandomVariable(inv_f,\"uniform distribution from x=1:5\")\n",
    "\n",
    "def two_linear_functions(x,slope1,slope2,intercept1,intercept2,std_dev1=1,std_dev2=1):\n",
    "    coin_toss = random.randint(0,1)\n",
    "    if coin_toss:\n",
    "        return (MC.Linear_GaussianNoise(x,slope1,intercept1,std_dev1))\n",
    "    else:\n",
    "        return (MC.Linear_GaussianNoise(x,slope2,intercept2,std_dev2))\n",
    "cost_f = lambda x : (x,two_linear_functions(x,1,0,0,0))\n",
    "generate_toy_data = MC.Simulator(X,cost_f,'generator for two linear functions from x=1:5', verbose = True)\n",
    "\n",
    "for y in generate_toy_data.sample_repeated(10):\n",
    "    print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "\n",
    "# Possible Tasks\n",
    "# Auto-encoding\n",
    "# Predicting next frame\n",
    "# regerssion\n",
    "\n",
    "\n",
    "# Free music arxiv (predict next frame)? \n",
    "# Face age (regression)?\n",
    "# Movie Data (predict next frame)?\n",
    "# Speech audio data (preidct next frame)?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (300, 1)\n",
      "300 train samples\n",
      "100 test samples\n",
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/12\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 134115.1877 - acc: 0.0000e+00 - val_loss: 111219.8125 - val_acc: 0.0000e+00\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 0s 22us/step - loss: 106435.7819 - acc: 0.0000e+00 - val_loss: 92853.9688 - val_acc: 0.0000e+00\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 0s 21us/step - loss: 94834.6369 - acc: 0.0000e+00 - val_loss: 86637.5938 - val_acc: 0.0000e+00\n",
      "Epoch 4/12\n",
      "300/300 [==============================] - 0s 20us/step - loss: 91627.6700 - acc: 0.0000e+00 - val_loss: 85806.1406 - val_acc: 0.0000e+00\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 0s 24us/step - loss: 90825.9404 - acc: 0.0000e+00 - val_loss: 83505.1953 - val_acc: 0.0000e+00\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 0s 22us/step - loss: 89924.2795 - acc: 0.0000e+00 - val_loss: 81983.3125 - val_acc: 0.0000e+00\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 0s 19us/step - loss: 89386.7283 - acc: 0.0000e+00 - val_loss: 81809.1797 - val_acc: 0.0000e+00\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 0s 24us/step - loss: 89301.2453 - acc: 0.0000e+00 - val_loss: 81715.6172 - val_acc: 0.0000e+00\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 0s 24us/step - loss: 89360.7069 - acc: 0.0000e+00 - val_loss: 80892.1016 - val_acc: 0.0000e+00\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 0s 20us/step - loss: 89188.4480 - acc: 0.0000e+00 - val_loss: 81424.4141 - val_acc: 0.0000e+00\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 0s 19us/step - loss: 89323.2452 - acc: 0.0000e+00 - val_loss: 80633.9062 - val_acc: 0.0000e+00\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 0s 24us/step - loss: 89148.8815 - acc: 0.0000e+00 - val_loss: 80391.0156 - val_acc: 0.0000e+00\n",
      "Test loss: 80391.02125\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "#######Construct Network#########\n",
    "#################################\n",
    "\n",
    "\n",
    "# Define sudoMin loss function\n",
    "\n",
    "\n",
    "# Convolutional layers\n",
    "\n",
    "# Example from Keras github\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "TrainData = list(generate_toy_data.sample_repeated(300))\n",
    "x_train, y_train  = zip(*TrainData)\n",
    "TestData = list(generate_toy_data.sample_repeated(100))\n",
    "x_test, y_test  = zip(*TestData)\n",
    "x_train = np.array(x_train,ndmin = 2).T\n",
    "y_train = np.array(y_train,ndmin = 2).T\n",
    "x_test = np.array(x_test,ndmin = 2).T\n",
    "y_test = np.array(y_test,ndmin = 2).T\n",
    "# the data, split between train and test sets\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121.73162629928191, 547.0830166317656, 389.09015879554374, 783.4356212513676, 345.09313006236056, 925.4470646198791, 543.672980249206, 143.45912342132638, 269.76613376821837, 187.9510028559146)\n",
      "(122.09134432875899, 0.3948482423968563, -1.1833091147115218, 782.8231720703151, 346.02323171904237, 0.26826831236316717, 1.347539482475953, 143.51698093274297, 270.13668203796095, 2.585402386881395)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"(x_train, y_train), (x_test, y_test) = \\n\\nif K.image_data_format() == 'channels_first':\\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\\n    input_shape = (1, img_rows, img_cols)\\nelse:\\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "# the data, split between train and test sets\n",
    "\"\"\"(x_train, y_train), (x_test, y_test) = \n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
