{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import importlib\n",
    "resources = importlib.import_module(\"resources\")\n",
    "import resources.MonteCarlo as MC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "my_seed = 2010\n",
    "random.seed(my_seed)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, BatchNormalization, Multiply, Lambda, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.initializers import RandomNormal, RandomUniform\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.constraints import NonNeg\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "Data = pd.read_csv('data/preprocessedlosAngParking/part-00000-a8814381-7490-4ac5-8769-145ad7e2824a-c000.csv').sample(frac = 1/5e3)\n",
    "Data['SN'] = pd.to_numeric(Data['SN'], errors ='coerce')\n",
    "Data['position'] = pd.to_numeric(Data['position'], errors ='coerce')\n",
    "Data = Data[['SN','position']]\n",
    "Data.dropna()\n",
    "Data = Data[Data['SN'] > 1.3e9]\n",
    "X = Data.values\n",
    "X = StandardScaler().fit_transform(X)\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "Data['Labels'] = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(yTrue,yPred):\n",
    "    #return K.sum(K.square(yTrue-yPred))\n",
    "    return K.sum(K.min(K.square(yTrue - yPred),axis = 1))\\\n",
    "    +lambd*K.sum(K.square(yTrue-yPred))\n",
    "def customMetric(yTrue,yPred):\n",
    "    #return K.sum(K.square(yTrue-yPred))\n",
    "    return K.max(K.min(K.abs(yTrue -yPred),axis = 1))\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 15000\n",
    "lambd  = 1e-6\n",
    "n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "no_output_range = [1]\n",
    "no_input = 1\n",
    "models = {}\n",
    "results = {}\n",
    "for i in no_output_range:\n",
    "    models[i] = []\n",
    "    results[i] = 0\n",
    "\n",
    "for i in range(n_clusters_):\n",
    "    X_i = Data[Data['Labels']==i]['SN'].values\n",
    "    Y_i = Data[Data['Labels']==i]['position'].values\n",
    "    for no_output in no_output_range:\n",
    "        Y_TRANSFORMED = np.repeat(Y_i.reshape((Y_i.shape[0],1)),no_output,axis=1)\n",
    "        _input_= keras.layers.Input(shape=(no_input,))\n",
    "    \n",
    "        neg_pos_mask = K.tf.constant(np.random.choice( [-1,1],[1,no_output]),dtype = tf.float32)\n",
    "        mask = Lambda( lambda x : neg_pos_mask)(_input_) # _input_ is just added to get this to compile\n",
    "\n",
    "        l1 = Dense(64, activation='linear', name=\"hidden_1_dense64\",\n",
    "                        kernel_initializer= RandomUniform(minval=1, maxval=2),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg(),                   \n",
    "                        input_shape=[no_input])(_input_)\n",
    "        l1a = LeakyReLU(alpha=0.1,name=\"hidden_1_leakyRelu\")(l1)\n",
    "        l1b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_1')(l1a)\n",
    "\n",
    "        l2 = Dense(32, activation='linear', name=\"hidden_2_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=1, maxval=2),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg())(l1b)\n",
    "        l2a = LeakyReLU(alpha=0.1,name=\"hidden_2_leakyRelu\")(l2)\n",
    "        l2a = l2\n",
    "        l2b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_2')(l2a)\n",
    "\n",
    "        l3 = Dense(32, activation='relu', name=\"hidden_3_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=.05, maxval=.15),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg())(l2b)\n",
    "        l3a = LeakyReLU(alpha=0.1,name=\"hidden_3_leakyRelu\")(l2)\n",
    "        l3a = l3\n",
    "        l3b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_3')(l3a)\n",
    "\n",
    "        l4 = Dense(no_output, activation='linear', name=\"hidden_4_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=.05, maxval=1),\n",
    "                        bias_initializer= RandomNormal(), kernel_constraint=NonNeg())(l3b)\n",
    "\n",
    "        #_output_ =l3\n",
    "        _output_ = Multiply()([l4,mask])\n",
    "\n",
    "        model = keras.models.Model(inputs=_input_ , outputs=_output_)\n",
    "\n",
    "        model.compile(loss=customLoss, metrics=[customMetric],\n",
    "                  optimizer=keras.optimizers.Nadam(lr=.01, beta_1=0.9, beta_2=0.999, clipvalue=0.5, schedule_decay=0.0001))\n",
    "\n",
    "        filepath = \"results\\parking_weights_cluster{}_output{}.hdf5\".format(i,no_output)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor=\"val_customMetric\", verbose=0, mode = 'min', save_best_only=True)\n",
    "        model.fit(X_i, Y_TRANSFORMED,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_i, Y_TRANSFORMED),\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=0)\n",
    "        model.load_weights(filepath)\n",
    "        score = model.evaluate(X_i, Y_TRANSFORMED, verbose=0)\n",
    "        print(score)\n",
    "        YPred= model.predict(X_i)\n",
    "        maxError = np.max(np.min(np.abs(YPred - Y_TRANSFORMED),axis=1),axis=0)\n",
    "        results[no_output] = max(results[no_output],maxError)\n",
    "        models[no_output].append(model)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_space = np.linspace(42.4e8, 43.44e8, 400)\n",
    "X = Data['SN'].values\n",
    "Y = Data['position'].values\n",
    "for no_output in no_output_range:\n",
    "    plt.clf()\n",
    "    plt.ylim(0,1e7)\n",
    "    plt.scatter(X, Y,s = .2, c='blue',marker= '^',zorder=2)\n",
    "    for i in range(n_clusters_):\n",
    "        filepath = \"results\\parking_weights_cluster{}_output{}.hdf5\".format(i,no_output)        \n",
    "        _input_= keras.layers.Input(shape=(no_input,))\n",
    "        neg_pos_mask = K.tf.constant(np.random.choice( [-1,1],[1,no_output]),dtype = tf.float32)\n",
    "        mask = Lambda( lambda x : neg_pos_mask)(_input_) # _input_ is just added to get this to compile\n",
    "\n",
    "        l1 = Dense(64, activation='linear', name=\"hidden_1_dense64\",\n",
    "                        kernel_initializer= RandomUniform(minval=1, maxval=2),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg(),                   \n",
    "                        input_shape=[no_input])(_input_)\n",
    "        l1a = LeakyReLU(alpha=0.1,name=\"hidden_1_leakyRelu\")(l1)\n",
    "        l1b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_1')(l1a)\n",
    "\n",
    "        l2 = Dense(32, activation='linear', name=\"hidden_2_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=1, maxval=2),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg())(l1b)\n",
    "        l2a = LeakyReLU(alpha=0.1,name=\"hidden_2_leakyRelu\")(l2)\n",
    "        l2a = l2\n",
    "        l2b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_2')(l2a)\n",
    "\n",
    "        l3 = Dense(32, activation='relu', name=\"hidden_3_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=.05, maxval=.15),\n",
    "                        bias_initializer=RandomUniform(), kernel_constraint=NonNeg())(l2b)\n",
    "        l3a = LeakyReLU(alpha=0.1,name=\"hidden_3_leakyRelu\")(l2)\n",
    "        l3a = l3\n",
    "        l3b = BatchNormalization(gamma_constraint=NonNeg(), name='batch_norm_3')(l3a)\n",
    "\n",
    "        l4 = Dense(no_output, activation='linear', name=\"hidden_4_dense64\",\n",
    "                        kernel_initializer=RandomUniform(minval=.05, maxval=1),\n",
    "                        bias_initializer= RandomNormal(), kernel_constraint=NonNeg())(l3b)\n",
    "        _output_ = Multiply()([l4,mask])\n",
    "        model = keras.models.Model(inputs=_input_ , outputs=_output_)\n",
    "        model.load_weights(filepath)\n",
    "        model_output_linespace = zip(*model.predict(X_space))\n",
    "        for Y_pred in model_output_linespace:\n",
    "            plt.plot(X_space,Y_pred, 'k',linewidth = 1, alpha = .6,zorder=1)\n",
    "    plt.savefig(\"results/Test_Parking_Cluster_{number}.jpg\".format(number = no_output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
